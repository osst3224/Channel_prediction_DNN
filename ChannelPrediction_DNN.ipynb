{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zmFQ9ZB-J9yp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import scipy.io\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = scipy.io.loadmat('H2.mat')\n",
        "t = 14*3000\n",
        "subcarriers = 8\n",
        "MIMO = 1\n",
        "H = mat['H'].T\n",
        "noise = True\n",
        "SNR_dB = 20\n",
        "if noise:\n",
        "  mat_noise = scipy.io.loadmat('H_noise2.mat')\n",
        "  H_noisy = mat_noise['H_noise'].T\n",
        "else:\n",
        "  H_noisy = np.zeros_like(H)"
      ],
      "metadata": {
        "id": "5chFtXno78OD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get to operate for both train and test dataset\n",
        "\n",
        "def dataset_MIMO(dataset, noisy_dataset, step, lookback=4, samples=100000, model_type='GRU', offset=0, horizon=0):\n",
        "  horizon = horizon-step\n",
        "\n",
        "  # Define lookback period and split inputs/labels\n",
        "  #subcarriers = 624 # Already defined above\n",
        "  sc = math.ceil(samples/(t-lookback*step))\n",
        "\n",
        "  if sc <= subcarriers:\n",
        "    inputs = np.zeros((sc*(t-lookback*step), lookback, 2*MIMO))\n",
        "    labels = np.zeros((sc*(t-lookback*step), 2*MIMO))\n",
        "    labels_clean = np.zeros((sc*(t-lookback*step), 2*MIMO))\n",
        "\n",
        "  else:\n",
        "    while sc <= subcarriers:\n",
        "      samples = samples*subcarriers/sc\n",
        "      sc = math.ceil(samples/(t-lookback*step))\n",
        "\n",
        "    print('Observe that the number of data points available in this setting are ' + str(samples))\n",
        "    inputs = np.zeros((samples, lookback, 2*MIMO))\n",
        "    labels = np.zeros((samples, 2*MIMO))\n",
        "    labels_clean = np.zeros((samples, 2*MIMO))\n",
        "\n",
        "  jump = 1\n",
        "  for i in range(0, sc*jump, jump):\n",
        "      p = 2*t*(i+offset) # To jump to the current subcarrier\n",
        "      for j in range(2*lookback*step, 2*t, 2):\n",
        "        for m in range(MIMO):\n",
        "\n",
        "          q = 2*subcarriers*t*m # To jump to the current antenna array (MIMO)\n",
        "          s = q+p+j-(2*lookback*step) # First index for retrieving data. The current position minus the lookback\n",
        "          e = q+p+j # Last index for retrieving data\n",
        "\n",
        "          c = int(i/jump)*(t-lookback*step) + int(j/2)-lookback*step # The current position to store data\n",
        "\n",
        "          inputs[c, :, 2*m] = dataset[s:e:2*step].reshape(lookback) + noisy_dataset[s:e:2*step].reshape(lookback)\n",
        "          inputs[c, :, 2*m+1] = dataset[s+1:e+1:2*step].reshape(lookback) + noisy_dataset[s+1:e+1:2*step].reshape(lookback)\n",
        "\n",
        "          labels_clean[c, 2*m:2 + 2*m] = dataset[e+2*horizon:e+2*horizon+2].reshape(-1,2)\n",
        "          labels[c, 2*m:2 + 2*m] = noisy_dataset[e+2*horizon:e+2*horizon+2].reshape(-1,2) + dataset[e+2*horizon:e+2*horizon+2].reshape(-1,2)\n",
        "\n",
        "  inputs = inputs[:samples]\n",
        "  labels = labels[:samples]\n",
        "  labels_clean = labels_clean[:samples]\n",
        "\n",
        "  return inputs, labels, labels_clean"
      ],
      "metadata": {
        "id": "jueaAe7wAQ2t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eDrcNYBR9fic"
      },
      "outputs": [],
      "source": [
        "# Get to operate for both train and test dataset\n",
        "\n",
        "def dataset_MIMO_trans(dataset, noisy_dataset, step, lookback=4, samples=100000, model_type='GRU', offset=0, horizon=0, past=0):\n",
        "  h = int(horizon/step)\n",
        "  horizon = horizon-step\n",
        "\n",
        "  # Define lookback period and split inputs/labels\n",
        "  #subcarriers = 624 # Already defined above\n",
        "  sc = math.ceil(samples/(t-lookback*step))\n",
        "\n",
        "  if sc <= subcarriers:\n",
        "    inputs = np.zeros((sc*(t-lookback*step), lookback, 2*MIMO))\n",
        "    labels = np.zeros((sc*(t-lookback*step), past+h, 2*MIMO))\n",
        "    labels_clean = np.zeros((sc*(t-lookback*step), past+h, 2*MIMO))\n",
        "\n",
        "  else:\n",
        "    while sc <= subcarriers:\n",
        "      samples = samples*subcarriers/sc\n",
        "      sc = math.ceil(samples/(t-lookback*step))\n",
        "\n",
        "    print('Observe that the number of data points available in this setting are ' + str(samples))\n",
        "    inputs = np.zeros((samples, lookback, 2*MIMO))\n",
        "    labels = np.zeros((samples, past+h, 2*MIMO))\n",
        "    labels_clean = np.zeros((samples, past+h, 2*MIMO))\n",
        "\n",
        "  jump = 20\n",
        "  for i in range(0, sc*jump, jump):\n",
        "      p = 2*t*(i+offset) # To jump to the current subcarrier\n",
        "      for j in range(2*lookback*step, 2*t, 2):\n",
        "        for m in range(MIMO):\n",
        "\n",
        "          q = 2*subcarriers*t*m # To jump to the current antenna array (MIMO)\n",
        "          s = q+p+j-(2*lookback*step) # First index for retrieving data. The current position minus the lookback\n",
        "          e = q+p+j # Last index for retrieving data\n",
        "\n",
        "          c = int(i/jump)*(t-lookback*step) + int(j/2)-lookback*step # The current position to store data\n",
        "\n",
        "          inputs[c, :, 2*m] = dataset[s:e:2*step].reshape(lookback) + noisy_dataset[s:e:2*step].reshape(lookback)\n",
        "          inputs[c, :, 2*m+1] = dataset[s+1:e+1:2*step].reshape(lookback) + noisy_dataset[s+1:e+1:2*step].reshape(lookback)\n",
        "\n",
        "          labels_clean[c, :, 2*m] = dataset[e-2*past*step:e+2*horizon+2:2*step,0]#.reshape(-1,1+past+h,2) #::ts_step , past*step\n",
        "          labels_clean[c, :, 2*m+1] = dataset[e-2*past*step+1:e+2*horizon+2+1:2*step,0]#.reshape(-1,1+past+h,2) #::ts_step , past*step\n",
        "          labels[c, :, 2*m] = noisy_dataset[e-2*past*step:e+2*horizon+2:2*step,0] + dataset[e-2*past*step:e+2*horizon+2:2*step,0]#.reshape(-1,1+past+h,2)\n",
        "          labels[c, :, 2*m+1] = noisy_dataset[e-2*past*step+1:e+2*horizon+2+1:2*step,0] + dataset[e-2*past*step+1:e+2*horizon+2+1:2*step,0]#.reshape(-1,1+past+h,2)\n",
        "\n",
        "  inputs = inputs[:samples]\n",
        "  labels = labels[:samples]\n",
        "  labels_clean = labels_clean[:samples]\n",
        "\n",
        "\n",
        "\n",
        "  return inputs, labels, labels_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "74IU1Hs-5B7a"
      },
      "outputs": [],
      "source": [
        "def scaler_transform(X_list):#, x_max, x_min):\n",
        "  if type(X_list) == list:\n",
        "    X_scaled = []\n",
        "    for X in X_list:\n",
        "      X_scaled.append((X-x_min)/(x_max-x_min))\n",
        "  else:\n",
        "    X_scaled = (X_list[0]-x_min)/(x_max-x_min)\n",
        "\n",
        "  return X_scaled\n",
        "\n",
        "\n",
        "def scaler_inv_transform(X_list):#, x_max, x_min):\n",
        "  if type(X_list) == list:\n",
        "    X_std = []\n",
        "    for X in X_list:\n",
        "      X_std.append(X * (x_max-x_min)+x_min)\n",
        "\n",
        "  else:\n",
        "    X_std = X_list * (x_max-x_min)+x_min\n",
        "\n",
        "  return X_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qrI5LiYWJ9y1"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The authors of the original transformer paper describe very succinctly what\n",
        "    the positional encoding layer does and why it is needed:\n",
        "\n",
        "    \"Since our model contains no recurrence and no convolution, in order for the\n",
        "    model to make use of the order of the sequence, we must inject some\n",
        "    information about the relative or absolute position of the tokens in the\n",
        "    sequence.\" (Vaswani et al, 2017)\n",
        "    Adapted from:\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dropout: float=0.1,\n",
        "        max_seq_len: int=5000,\n",
        "        d_model: int=512,\n",
        "        batch_first: bool=False\n",
        "        ):\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "            dropout: the dropout rate\n",
        "            max_seq_len: the maximum length of the input sequences\n",
        "            d_model: The dimension of the output of sub-layers in the model\n",
        "                     (Vaswani et al, 2017)\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "        self.x_dim = 1 if batch_first else 0\n",
        "\n",
        "        # copy pasted from PyTorch tutorial\n",
        "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        #pe = torch.zeros(max_seq_len, 1, d_model)\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        #pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        #pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        #pe = torch.zeros(1, max_seq_len, d_model)\n",
        "        #pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        #pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or\n",
        "               [enc_seq_len, batch_size, dim_val]\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(self.x_dim)]\n",
        "\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "DQGEZRaxpOXk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "        input_size: int,\n",
        "        dec_seq_len: int,\n",
        "        batch_first: bool,\n",
        "        max_seq_len: int,\n",
        "        out_seq_len: int=1,\n",
        "        dim_val: int=512,\n",
        "        n_encoder_layers: int=4,\n",
        "        n_decoder_layers: int=4,\n",
        "        n_heads: int=8,\n",
        "        dropout_encoder: float=0.2,\n",
        "        dropout_decoder: float=0.2,\n",
        "        dropout_pos_enc: float=0.1,\n",
        "        dim_feedforward_encoder: int=2048,\n",
        "        dim_feedforward_decoder: int=2048,\n",
        "        num_predicted_features: int=2*MIMO\n",
        "        ):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_size: int, number of input variables. 1 if univariate.\n",
        "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
        "            dim_val: int, aka d_model. All sub-layers in the model produce\n",
        "                     outputs of dimension dim_val\n",
        "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
        "            n_decoder_layers: int, number of stacked encoder layers in the decoder\n",
        "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
        "            dropout_encoder: float, the dropout rate of the encoder\n",
        "            dropout_decoder: float, the dropout rate of the decoder\n",
        "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
        "            dim_feedforward_encoder: int, number of neurons in the linear layer\n",
        "                                     of the encoder\n",
        "            dim_feedforward_decoder: int, number of neurons in the linear layer\n",
        "                                     of the decoder\n",
        "            num_predicted_features: int, the number of features you want to predict.\n",
        "                                    Most of the time, this will be 1 because we're\n",
        "                                    only forecasting FCR-N prices in DK2, but in\n",
        "                                    we wanted to also predict FCR-D with the same\n",
        "                                    model, num_predicted_features should be 2.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec_seq_len = dec_seq_len\n",
        "\n",
        "        #print(\"input_size is: {}\".format(input_size))\n",
        "        #print(\"dim_val is: {}\".format(dim_val))\n",
        "\n",
        "        # Creating the three linear layers needed for the model\n",
        "        self.encoder_input_layer = nn.Linear(\n",
        "            in_features=input_size,\n",
        "            out_features=dim_val\n",
        "            )\n",
        "\n",
        "        self.decoder_input_layer = nn.Linear(\n",
        "            in_features=num_predicted_features,\n",
        "            out_features=dim_val\n",
        "            )\n",
        "\n",
        "        self.linear_mapping = nn.Linear(\n",
        "            in_features=dim_val,\n",
        "            out_features=num_predicted_features\n",
        "            )\n",
        "\n",
        "        # Create positional encoder\n",
        "        self.positional_encoding_layer = PositionalEncoder(\n",
        "            d_model=dim_val,\n",
        "            dropout=dropout_pos_enc,\n",
        "            batch_first=batch_first,\n",
        "            max_seq_len=max_seq_len\n",
        "            )\n",
        "\n",
        "        # The encoder layer used in the paper is identical to the one used by\n",
        "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=dim_val,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward_encoder,\n",
        "            dropout=dropout_encoder,\n",
        "            batch_first=batch_first\n",
        "            )\n",
        "\n",
        "        # Stack the encoder layers in nn.TransformerDecoder\n",
        "        # It seems the option of passing a normalization instance is redundant\n",
        "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
        "        # after each sub-layer\n",
        "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=encoder_layer,\n",
        "            num_layers=n_encoder_layers,\n",
        "            norm=None\n",
        "            )\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=dim_val,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=dim_feedforward_decoder,\n",
        "            dropout=dropout_decoder,\n",
        "            batch_first=batch_first\n",
        "            )\n",
        "\n",
        "        # Stack the decoder layers in nn.TransformerDecoder\n",
        "        # It seems the option of passing a normalization instance is redundant\n",
        "        # in my case, because nn.TransformerDecoderLayer per default normalizes\n",
        "        # after each sub-layer\n",
        "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            decoder_layer=decoder_layer,\n",
        "            num_layers=n_decoder_layers,\n",
        "            norm=None\n",
        "            )\n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor=None,\n",
        "                tgt_mask: Tensor=None) -> Tensor:\n",
        "        \"\"\"\n",
        "        Returns a tensor of shape:\n",
        "        [target_sequence_length, batch_size, num_predicted_features]\n",
        "\n",
        "        Args:\n",
        "            src: the encoder's output sequence. Shape: (S,E) for unbatched input,\n",
        "                 (S, N, E) if batch_first=False or (N, S, E) if\n",
        "                 batch_first=True, where S is the source sequence length,\n",
        "                 N is the batch size, and E is the number of features (1 if univariate)\n",
        "            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input,\n",
        "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if\n",
        "                 batch_first=True, where T is the target sequence length,\n",
        "                 N is the batch size, and E is the number of features (1 if univariate)\n",
        "            src_mask: the mask for the src sequence to prevent the model from\n",
        "                      using data points from the target sequence\n",
        "            tgt_mask: the mask for the tgt sequence to prevent the model from\n",
        "                      using data points from the target sequence\n",
        "        \"\"\"\n",
        "\n",
        "        #print(\"From model.forward(): Size of src as given to forward(): {}\".format(src.size()))\n",
        "        #print(\"From model.forward(): tgt size = {}\".format(tgt.size()))\n",
        "\n",
        "        # Pass throguh the input layer right before the encoder\n",
        "        src = self.encoder_input_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
        "        #print(\"From model.forward(): Size of src after input layer: {}\".format(src.size()))\n",
        "\n",
        "        # Pass through the positional encoding layer\n",
        "        src = self.positional_encoding_layer(src) # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
        "        #print(\"From model.forward(): Size of src after pos_enc layer: {}\".format(src.size()))\n",
        "\n",
        "        # Pass through all the stacked encoder layers in the encoder\n",
        "        # Masking is only needed in the encoder if input sequences are padded\n",
        "        # which they are not in this time series use case, because all my\n",
        "        # input sequences are naturally of the same length.\n",
        "        # (https://github.com/huggingface/transformers/issues/4083)\n",
        "        src = self.encoder( # src shape: [batch_size, enc_seq_len, dim_val]\n",
        "            src=src\n",
        "            )\n",
        "        #print(\"From model.forward(): Size of src after encoder: {}\".format(src.size()))\n",
        "\n",
        "        # Pass decoder input through decoder input layer\n",
        "        decoder_output = self.decoder_input_layer(tgt) # src shape: [target sequence length, batch_size, dim_val] regardless of number of input features\n",
        "        #print(\"From model.forward(): Size of decoder_output after linear decoder layer: {}\".format(decoder_output.size()))\n",
        "\n",
        "        #if src_mask is not None:\n",
        "            #print(\"From model.forward(): Size of src_mask: {}\".format(src_mask.size()))\n",
        "        #if tgt_mask is not None:\n",
        "            #print(\"From model.forward(): Size of tgt_mask: {}\".format(tgt_mask.size()))\n",
        "\n",
        "        # Pass throguh decoder - output shape: [batch_size, target seq len, dim_val]\n",
        "        decoder_output = self.decoder(\n",
        "            tgt=decoder_output,\n",
        "            memory=src,\n",
        "            tgt_mask=tgt_mask,\n",
        "            memory_mask=src_mask\n",
        "            )\n",
        "\n",
        "        # Pass through linear mapping\n",
        "        decoder_output = self.linear_mapping(decoder_output) # shape [batch_size, target seq len]\n",
        "        #print(\"From model.forward(): decoder_output size after linear_mapping = {}\".format(decoder_output.size()))\n",
        "\n",
        "        return decoder_output"
      ],
      "metadata": {
        "id": "_Z3bqmZ9gD3K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_src_trg(\n",
        "        self,\n",
        "        sequence: torch.Tensor,\n",
        "        enc_seq_len: int,\n",
        "        target_seq_len: int\n",
        "        ): #-> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
        "\n",
        "        \"\"\"\n",
        "        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n",
        "        sequences from a sequence.\n",
        "        Args:\n",
        "            sequence: tensor, a 1D tensor of length n where\n",
        "                    n = encoder input length + target sequence length\n",
        "            enc_seq_len: int, the desired length of the input to the transformer encoder\n",
        "            target_seq_len: int, the desired length of the target sequence (the\n",
        "                            one against which the model output is compared)\n",
        "        Return:\n",
        "            src: tensor, 1D, used as input to the transformer model\n",
        "            trg: tensor, 1D, used as input to the transformer model\n",
        "            trg_y: tensor, 1D, the target sequence against which the model output\n",
        "                is compared when computing loss.\n",
        "\n",
        "        \"\"\"\n",
        "        #print(\"Called dataset.TransformerDataset.get_src_trg\")\n",
        "        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
        "\n",
        "        #print(\"From data.TransformerDataset.get_src_trg: sequence shape: {}\".format(sequence.shape))\n",
        "\n",
        "        # encoder input\n",
        "        src = sequence[:enc_seq_len]\n",
        "\n",
        "        # decoder input. As per the paper, it must have the same dimension as the\n",
        "        # target sequence, and it must contain the last value of src, and all\n",
        "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
        "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
        "\n",
        "        trg = trg[:, 0]\n",
        "\n",
        "        if len(trg.shape) == 1:\n",
        "\n",
        "            trg = trg.unsqueeze(-1)\n",
        "\n",
        "\n",
        "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
        "\n",
        "        # The target sequence against which the model output will be compared to compute loss\n",
        "        trg_y = sequence[-target_seq_len:]\n",
        "\n",
        "\n",
        "        # We only want trg_y to consist of the target variable not any potential exogenous variables\n",
        "        trg_y = trg_y[:, 0]\n",
        "\n",
        "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
        "\n",
        "        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len]"
      ],
      "metadata": {
        "id": "-WeHKPzxJdZ-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(dim1: int, dim2: int) -> Tensor:\n",
        "    \"\"\"\n",
        "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
        "    Source:\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    Args:\n",
        "        dim1: int, for both src and tgt masking, this must be target sequence\n",
        "              length\n",
        "        dim2: int, for src masking this must be encoder sequence length (i.e.\n",
        "              the length of the input sequence to the model),\n",
        "              and for tgt masking, this must be target sequence length\n",
        "    Return:\n",
        "        A Tensor of shape [dim1, dim2]\n",
        "    \"\"\"\n",
        "    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)"
      ],
      "metadata": {
        "id": "bnZlLdQrLtj5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GOE2tiRmJ9y3"
      },
      "outputs": [],
      "source": [
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
        "        super(GRUNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.gru(x, h)\n",
        "        out = self.fc(self.tanh(out[:,-1]))\n",
        "        return out, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
        "\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KsZnOcFoJ9y6"
      },
      "outputs": [],
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.lstm(x, h)\n",
        "        out = self.fc(self.tanh(out[:,-1]))\n",
        "        return out, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "class CNNNet1(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(CNNNet1, self).__init__()\n",
        "        self.kernel_size = 6\n",
        "\n",
        "        # conv layer\n",
        "        downsample = self._downsample(32, 32)\n",
        "        self.conv1 = nn.Conv1d(in_channels=2,\n",
        "                               out_channels=4,\n",
        "                               kernel_size=self.kernel_size,\n",
        "                               stride=downsample,\n",
        "                               padding=self._padding(downsample),\n",
        "                               bias=False)\n",
        "                # ReLU\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "        self.maxpool1d = nn.MaxPool1d(kernel_size = self.kernel_size,\n",
        "                                      stride = downsample,\n",
        "                                      padding = self._padding(downsample))\n",
        "\n",
        "        # conv layer\n",
        "        downsample = self._downsample(32, 32)\n",
        "        self.conv2 = nn.Conv1d(in_channels=4,\n",
        "                               out_channels=8,\n",
        "                               kernel_size=self.kernel_size,\n",
        "                               stride=downsample,\n",
        "                               padding=self._padding(downsample),\n",
        "                               bias=False)\n",
        "         # conv layer\n",
        "        downsample = self._downsample(32, 16)\n",
        "        self.conv3 = nn.Conv1d(in_channels=8,\n",
        "                               out_channels=16,\n",
        "                               kernel_size=self.kernel_size,\n",
        "                               stride=downsample,\n",
        "                               padding=self._padding(downsample),\n",
        "                               bias=False)\n",
        "        # conv layer\n",
        "        downsample = self._downsample(16, 8)\n",
        "        self.conv4 = nn.Conv1d(in_channels=16,\n",
        "                               out_channels=32,\n",
        "                               kernel_size=self.kernel_size,\n",
        "                               stride=downsample,\n",
        "                               padding=self._padding(downsample),\n",
        "                               bias=False)\n",
        "\n",
        "        # linear layer\n",
        "        self.lin = nn.Linear(in_features=80,\n",
        "                             out_features=2)\n",
        "\n",
        "\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "      def _padding(self, downsample):\n",
        "        return max(0, int(np.floor((self.kernel_size - downsample + 1) / 2)))\n",
        "\n",
        "      def _downsample(self, seq_len_in, seq_len_out):\n",
        "        return int(seq_len_in // seq_len_out)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "        x= x.transpose(2,1)\n",
        "\n",
        "        x = self.leaky_relu(self.conv1(x))\n",
        "        x = self.maxpool1d(x)\n",
        "        x = self.leaky_relu(self.conv2(x))\n",
        "        x = self.maxpool1d(x)\n",
        "        x = self.leaky_relu(self.conv3(x))\n",
        "        x = self.maxpool1d(x)\n",
        "        #x = self.leaky_relu(self.conv4(x))\n",
        "        #x = self.maxpool1d(x)\n",
        "        #x = self.relu(self.conv2(x))\n",
        "        x_flat= x.view(x.size(0), -1)\n",
        "        x = self.lin(x_flat)\n",
        "\n",
        "        #x = self.sigmoid(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "gTewJbI8_GpH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9YqYmwTiY8Ba"
      },
      "outputs": [],
      "source": [
        "# MLP\n",
        "class MLPNet(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(input_dim, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, output_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def AR_coeff_LS(data, lookback, la):\n",
        "  F = np.zeros([lookback, lookback])\n",
        "  A = np.zeros([len(data), 2*MIMO, lookback])\n",
        "  for i in range(len(data)):\n",
        "    for m in range(2*MIMO):\n",
        "      for l in range(lookback):\n",
        "        b = np.flip(data[i, l:l+lookback, m])\n",
        "        F[l,:] = b\n",
        "      a = np.matrix(data[i, lookback:, m]).T*F[0,0]\n",
        "\n",
        "      c = F*F[0,0]\n",
        "      ca = np.linalg.inv(c.T@c + la*np.eye(c.shape[0]))@(c.T)@a\n",
        "      A[i, m, :] = ca.T\n",
        "\n",
        "  return A"
      ],
      "metadata": {
        "id": "yZcXO-3-DYyG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9uxaizu1Ty9o"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, model_type='regular'):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    if model_type in ['GRU', 'LSTM']:\n",
        "      h = model.init_hidden(batch_size)\n",
        "      for x, label, clean_label in train_loader:\n",
        "          optimizer.zero_grad()\n",
        "          out, _ = model(x.to(device).float(), h)\n",
        "          loss = criterion(out, label.to(device).float())\n",
        "          loss.backward()#retain_graph=True)\n",
        "          optimizer.step()\n",
        "          loss = criterion(torch.from_numpy(scaler_inv_transform(out.cpu().detach().numpy())),\n",
        "                           torch.from_numpy(clean_label.numpy()))\n",
        "          train_loss += loss.item()\n",
        "\n",
        "\n",
        "    elif model_type == 'TRANS':\n",
        "      for x, label, clean_label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        src = x[:,:enc_seq_len,:]\n",
        "        tgt = x[:,-dec_seq_len:,:]\n",
        "        out = model(src.to(device).float(), tgt.to(device).float(), src_mask=src_mask.to(device).float(), tgt_mask=tgt_mask.to(device).float())\n",
        "        loss = criterion(out, label.to(device).float())\n",
        "        loss.backward()#retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = criterion(torch.from_numpy(scaler_inv_transform(out.cpu().detach().numpy()))[:,-1,:],\n",
        "                         torch.from_numpy(clean_label.numpy())[:,-1,:])\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          x, label, clean_label = data\n",
        "          optimizer.zero_grad()\n",
        "          out = model(x.to(device).float())\n",
        "          loss = criterion(out, label.to(device).float())\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          loss = criterion(torch.from_numpy(scaler_inv_transform(out.cpu().detach().numpy())),\n",
        "                           torch.from_numpy(clean_label.numpy()))\n",
        "          train_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return train_loss/len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rIZXb5o_RCbh"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_x, test_y_clean, test_y, model_type, epoch):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    inp = torch.from_numpy(test_x)\n",
        "    target = torch.from_numpy(test_y_clean)\n",
        "    labs_dist = torch.from_numpy(test_y)\n",
        "    target_measured = scaler_inv_transform(labs_dist.numpy())\n",
        "\n",
        "    if (model_type == 'GRU' or model_type == 'LSTM'):\n",
        "      h = model.init_hidden(inp.shape[0])\n",
        "      out, _ = model(inp.to(device).float(), h)\n",
        "      output = scaler_inv_transform(out.cpu().detach().numpy())\n",
        "      loss = criterion(torch.from_numpy(output), target)\n",
        "\n",
        "    elif model_type == 'TRANS':\n",
        "      src = inp[:,:enc_seq_len,:]\n",
        "      tgt = inp[:,-dec_seq_len:,:]\n",
        "      start_time = time.time()\n",
        "      out = model(src.to(device).float(), tgt.to(device).float(), src_mask=src_mask.to(device).float(), tgt_mask=tgt_mask.to(device).float())\n",
        "      output = scaler_inv_transform(out.cpu().detach().numpy())\n",
        "      loss = criterion(torch.from_numpy(output)[:,-1,:],\n",
        "                       target[:,-1,:])\n",
        "\n",
        "    else:\n",
        "      out = model(inp.to(device).float())\n",
        "      output = scaler_inv_transform(out.cpu().detach().numpy())\n",
        "      loss = criterion(torch.from_numpy(output), target)\n",
        "\n",
        "    test_loss = loss.item()\n",
        "    target = target.numpy()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T-6JYdbOKhl8"
      },
      "outputs": [],
      "source": [
        "def epoch_loop(model, train_loader, test_x, test_y, test_y_clean, epochs, lr_scheduler1, model_type = 'GRU'):\n",
        "  print('Started with ' + model_type)\n",
        "\n",
        "  training_loss = np.zeros([epochs])\n",
        "  validation_loss = np.zeros([epochs])\n",
        "  start_time = time.time()\n",
        "  best_loss = 1\n",
        "\n",
        "  for epoch in range(1,epochs+1):\n",
        "    training_loss[epoch-1] = train(model, train_loader, model_type)\n",
        "    validation_loss[epoch-1] = evaluate(model, test_x, test_y_clean, test_y, model_type, epoch)\n",
        "\n",
        "    if 1:#epoch%10 == 0:\n",
        "      current_time = time.time()\n",
        "      print(\"Epoch {}/{} Done\".format(epoch, epochs))\n",
        "      print(\"Total Time Elapsed: %.2f minutes\" %((current_time-start_time)/60))\n",
        "      print(\"Training loss: %.6f \" %(training_loss[epoch-1]))\n",
        "      print(\"Validation loss: %.6f \" %(validation_loss[epoch-1]))\n",
        "\n",
        "    if lr_scheduler1:\n",
        "      lr_scheduler1.step()\n",
        "\n",
        "  return training_loss, validation_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "L0SSj2ir4uoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6088795d-7365-40b1-e6d4-9a03ed6ce387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe448d981d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3zRX2N_wjWr1"
      },
      "outputs": [],
      "source": [
        "lr = 0.00008\n",
        "lr_rnn = 0.00008\n",
        "lr_trans = 0.00008\n",
        "ts_step = np.array([14])\n",
        "horizons = np.array([14, 28, 42, 56, 70, 84, 98, 112, 126, 140, 154, 168, 196, 210])\n",
        "train_samples = 9000\n",
        "test_samples = 1000\n",
        "samples = 10000\n",
        "lookback = 5\n",
        "order = 4\n",
        "test_sc_offset = 5\n",
        "batch_size = 32\n",
        "hidden = 150\n",
        "epochs = 200\n",
        "epochs_rnn = 200\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "file = 'drive/MyDrive/performance_SNR20.csv'\n",
        "if os.path.isfile(file):\n",
        "  performance_df = pd.read_csv(file, index_col=0)\n",
        "  cols = list(performance_df.columns)\n",
        "  if len(performance_df.index) is not len(horizons):\n",
        "    mask = np.isin(horizons, np.array(performance_df.index))\n",
        "    diff = horizons[np.invert(mask)]\n",
        "    for d in diff:\n",
        "      performance_df.loc[d] = np.zeros(len(cols))\n",
        "else:\n",
        "  performance_df = pd.DataFrame(columns=['Outdated', 'MLP', 'CNN', 'GRU', 'LSTM', 'KF', 'Transformer'], index=horizons)\n",
        "  for col in performance_df.columns:\n",
        "    performance_df[col].values[:] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a_ZDDmmCEnW3"
      },
      "outputs": [],
      "source": [
        "outdated_error =        np.zeros([len(horizons)])\n",
        "training_loss_gru =     np.zeros([len(horizons), epochs_rnn])\n",
        "validation_loss_gru =   np.zeros([len(horizons), epochs_rnn])\n",
        "training_loss_lstm =    np.zeros([len(horizons), epochs_rnn])\n",
        "validation_loss_lstm =  np.zeros([len(horizons), epochs_rnn])\n",
        "training_loss_mlp =     np.zeros([len(horizons), epochs])\n",
        "validation_loss_mlp =   np.zeros([len(horizons), epochs])\n",
        "training_loss_cnn =     np.zeros([len(horizons), epochs])\n",
        "validation_loss_cnn =   np.zeros([len(horizons), epochs])\n",
        "training_loss_transformer =   np.zeros([len(horizons), epochs])\n",
        "validation_loss_transformer = np.zeros([len(horizons), epochs])\n",
        "y_pred = np.zeros([test_samples, 2*MIMO])\n",
        "y_pred_err = np.zeros([len(horizons)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(horizons)):\n",
        "\n",
        "  # Creating dataset\n",
        "  train_x, train_y, train_y_clean = dataset_MIMO(H, H_noisy, ts_step[0], lookback, train_samples, 'GRU', horizon=horizons[i])\n",
        "  test_x, test_y, test_y_clean = dataset_MIMO(H, H_noisy, ts_step[0], lookback, test_samples, 'GRU', test_sc_offset, horizon=horizons[i])\n",
        "  X = np.append(np.append(train_x, test_x), np.append(train_y, test_y))\n",
        "  x_max = np.max(X)\n",
        "  x_min = np.min(X)\n",
        "  [train_x, train_y] = scaler_transform([train_x, train_y])\n",
        "  [test_x, test_y] = scaler_transform([test_x, test_y])\n",
        "  train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y), torch.from_numpy(train_y_clean))\n",
        "  train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True, shuffle = False)\n",
        "\n",
        "  # GRU\n",
        "  if 0:#not performance_df.loc[horizons[i], 'GRU']:\n",
        "    criterion = nn.MSELoss()\n",
        "    gru_model = GRUNet(input_dim=next(iter(train_loader))[0].shape[2], hidden_dim = hidden, output_dim = 2*MIMO, n_layers = 3)\n",
        "    gru_model.to(device)\n",
        "    optimizer = torch.optim.Adam(gru_model.parameters(), lr=lr_rnn)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(np.arange(start=10, stop=200, step=10)), gamma=0.6)\n",
        "    training_loss_gru[i, :], validation_loss_gru[i, :] = epoch_loop(gru_model, train_loader, test_x, test_y, test_y_clean,\n",
        "                                                                                 epochs_rnn, lr_scheduler, model_type = 'GRU')\n",
        "    performance_df.loc[horizons[i], 'GRU'] = min(validation_loss_gru[i, :])\n",
        "    performance_df.to_csv(file)\n",
        "\n",
        "\n",
        "  #LSTM\n",
        "  if 0:#not performance_df.loc[horizons[i], 'LSTM']:\n",
        "    lstm_model = LSTMNet(input_dim=next(iter(train_loader))[0].shape[2], hidden_dim = hidden, output_dim = 2*MIMO, n_layers = 3)\n",
        "    lstm_model.to(device)\n",
        "    optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr_rnn)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(np.arange(start=10, stop=200, step=10)), gamma=0.6)\n",
        "    training_loss_lstm[i, :], validation_loss_lstm[i, :] = epoch_loop(lstm_model, train_loader, test_x, test_y, test_y_clean,\n",
        "                                                                                    epochs_rnn, lr_scheduler, model_type = 'LSTM')\n",
        "    performance_df.loc[horizons[i], 'LSTM'] = min(validation_loss_lstm[i, :])\n",
        "    performance_df.to_csv(file)\n",
        "\n",
        "  #CNN\n",
        "  if 0:#not performance_df.loc[horizons[i], 'CNN']:\n",
        "    train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y), torch.from_numpy(train_y_clean))\n",
        "    train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
        "    cnn_model = CNNNet1()\n",
        "    cnn_model.to(device)\n",
        "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=lr)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(np.arange(start=10, stop=200, step=10)), gamma=0.6)\n",
        "    training_loss_cnn[i, :], validation_loss_cnn[i, :], = epoch_loop(cnn_model, train_loader, test_x, test_y, test_y_clean,\n",
        "                                                                                 epochs, lr_scheduler, model_type = 'CNN')\n",
        "    performance_df.loc[horizons[i], 'CNN'] = min(validation_loss_cnn[i, :])\n",
        "    performance_df.to_csv(file)\n",
        "\n",
        "\n",
        "  train_x = train_x.reshape(train_x.shape[0], 1, train_x.shape[1], train_x.shape[2])\n",
        "  test_x = test_x.reshape(test_x.shape[0], 1, test_x.shape[1], test_x.shape[2])\n",
        "  #MLP\n",
        "  train_x = train_x.reshape(train_x.shape[0], train_x.shape[2]*train_x.shape[3]) #MLP\n",
        "  test_x = test_x.reshape(test_x.shape[0], test_x.shape[2]*test_x.shape[3]) #MLP\n",
        "  if 0:#not performance_df.loc[horizons[i], 'MLP']:\n",
        "    train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y), torch.from_numpy(train_y_clean))\n",
        "    train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
        "    mlp_model = MLPNet(input_dim=2*MIMO*lookback, output_dim = 2*MIMO)\n",
        "    mlp_model.to(device)\n",
        "    optimizer = torch.optim.Adam(mlp_model.parameters(), lr=lr)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(np.arange(start=10, stop=200, step=10)), gamma=0.6)\n",
        "    training_loss_mlp[i, :], validation_loss_mlp[i, :] = epoch_loop(mlp_model, train_loader, test_x, test_y, test_y_clean,\n",
        "                                                                                 epochs, lr_scheduler, model_type = 'MLP')\n",
        "    performance_df.loc[horizons[i], 'MLP'] = min(validation_loss_mlp[i, :])\n",
        "    performance_df.to_csv(file)\n",
        "\n",
        "  # Outdated\n",
        "  if 0:#not performance_df.loc[horizons[i], 'Outdated']:\n",
        "    performance_df.loc[horizons[i], 'Outdated'] = np.mean(abs(scaler_inv_transform(test_x[:, -2*MIMO:])-test_y_clean)**2)\n",
        "    performance_df.to_csv(file)\n",
        "    NMSE = (np.linalg.norm(scaler_inv_transform(test_x[:, -2*MIMO:])-test_y_clean, axis=1)**2)/(np.linalg.norm(test_y_clean, axis=1)**2)\n",
        "\n",
        "  print('Sampling time ' + str(horizons[i]/14) + ' ms done.')"
      ],
      "metadata": {
        "id": "JyXPygw5G0pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model parameters\n",
        "dim_val = 128  # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
        "n_heads = 4 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
        "n_encoder_layers = 1 # Number of times the encoder layer is stacked in the encoder\n",
        "n_decoder_layers = 1 # Number of times the decoder layer is stacked in the decoder\n",
        "input_size = 2*MIMO # The number of input variables. 1 if univariate forecasting.\n",
        "enc_seq_len = 5  # length of input given to encoder. Can have any integer value.\n",
        "dec_seq_len = 2 # length of input given to decoder. Can have any integer value.\n",
        "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoderdropout_encoder: float=0.2,"
      ],
      "metadata": {
        "id": "78_pCJNR9bRn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl3gIQn7qEHy"
      },
      "outputs": [],
      "source": [
        "# Implement more decoder sequences\n",
        "\n",
        "for i in range(len(horizons)):\n",
        "    output_sequence_length = int(horizons[i]/ts_step[0]) # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
        "    # Creating dataset\n",
        "    train_x, train_y, train_y_clean = dataset_MIMO_trans(H, H_noisy, ts_step[0], enc_seq_len, train_samples, 'TRANS', horizon=horizons[i], past=dec_seq_len-output_sequence_length)\n",
        "    test_x, test_y, test_y_clean = dataset_MIMO_trans(H, H_noisy, ts_step[0], enc_seq_len, test_samples, 'TRANS', test_sc_offset, horizon=horizons[i], past=dec_seq_len-output_sequence_length)\n",
        "    X = np.append(np.append(train_x, test_x), np.append(train_y, test_y))\n",
        "    x_max = np.max(X)\n",
        "    x_min = np.min(X)\n",
        "    [train_x, train_y] = scaler_transform([train_x, train_y])\n",
        "    [test_x, test_y] = scaler_transform([test_x, test_y])\n",
        "    train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y), torch.from_numpy(train_y_clean))\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=True, shuffle = False)\n",
        "\n",
        "    # Transfomers\n",
        "    if 1:\n",
        "      criterion = nn.MSELoss()\n",
        "      ## Model parameters\n",
        "\n",
        "      # Make src mask for decoder with size:\n",
        "      tgt_mask = generate_square_subsequent_mask(\n",
        "          dim1=dec_seq_len, #output_sequence_length,\n",
        "          dim2=dec_seq_len, #output_sequence_length\n",
        "         )\n",
        "      src_mask = generate_square_subsequent_mask(\n",
        "          dim1=dec_seq_len, #output_sequence_length,\n",
        "          dim2=enc_seq_len # Check memory mask and padding\n",
        "          )\n",
        "\n",
        "      trans_model = TimeSeriesTransformer(\n",
        "      dim_val=dim_val,\n",
        "      input_size=input_size,\n",
        "      dec_seq_len=dec_seq_len,\n",
        "      batch_first=True,\n",
        "      max_seq_len=max_seq_len,\n",
        "      out_seq_len=output_sequence_length,\n",
        "      n_decoder_layers=n_decoder_layers,\n",
        "      n_encoder_layers=n_encoder_layers,\n",
        "      n_heads=n_heads,\n",
        "      dropout_encoder=0.1,\n",
        "      dropout_decoder=0.1,\n",
        "      dropout_pos_enc=0.1,\n",
        "      dim_feedforward_encoder=512,#1024,\n",
        "      dim_feedforward_decoder=512)#)\n",
        "\n",
        "      trans_model.to(device)\n",
        "\n",
        "      optimizer = torch.optim.Adam(trans_model.parameters(), lr=lr_trans)\n",
        "      lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(np.arange(start=10, stop=200, step=10)), gamma=0.8)\n",
        "      optimizer = torch.optim.Adam(trans_model.parameters(), lr=lr_trans)\n",
        "      training_loss_transformer[i, :], validation_loss_transformer[i, :] = epoch_loop(trans_model, train_loader, test_x, test_y, test_y_clean,\n",
        "                                                                                                           epochs, lr_scheduler, model_type = 'TRANS')\n",
        "      performance_df.loc[horizons[i], 'Transformer'] = min(validation_loss_transformer[i, :])\n",
        "      performance_df.to_csv(file)\n",
        "\n",
        "    train_y = train_y[:,-1,:]\n",
        "    train_y_clean = train_y_clean[:,-1,:]\n",
        "    test_y = test_y[:,-1,:]\n",
        "    test_y_clean = test_y_clean[:,-1,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kalman filtering\n",
        "MIMO = 4\n",
        "for j in range(len(horizons)):\n",
        "  train_x, train_y, train_y_clean = dataset_MIMO(H.__deepcopy__(1), H_noisy.__deepcopy__(1), horizons[j], 2*order, test_samples, 'GRU', horizon=horizons[j])\n",
        "  A = AR_coeff_LS(train_x.__deepcopy__(1), order, 0.1)\n",
        "  s = int(A.shape[1]/2)\n",
        "  C = np.zeros([1,s])\n",
        "  C[0] = 1\n",
        "  Q = np.eye(s)\n",
        "  R = 1\n",
        "  y_pred = np.zeros([A.shape[0], 2*MIMO])\n",
        "  y_est = np.zeros([A.shape[0], 2*MIMO])\n",
        "  y_pred_err = np.zeros([len(horizons)])\n",
        "  for m in range(2*MIMO):\n",
        "    P = np.eye(s)\n",
        "    for i in range(A.shape[0]):\n",
        "      M = np.zeros([s,s])\n",
        "      M[0,:] = A[i,m,:4]\n",
        "      M[1,0] = 1\n",
        "      M[2,1] = 1\n",
        "      M[3,2] = 1\n",
        "      x_pred = (M@np.flip(train_x[i,4:,m])).reshape(s,1)\n",
        "      y_pred[i, m] = x_pred[0]\n",
        "      P_pred = M@P@M.T + Q\n",
        "      innovation = (train_y[i,m] - C@x_pred).reshape(1,1)\n",
        "      S = C@P_pred@C.T + 0\n",
        "      K = P_pred@C.T@np.linalg.inv(S)\n",
        "      K = K.reshape(K.shape[0], 1)\n",
        "      P = (np.eye(s) - C@K)@P_pred\n",
        "      x_est = x_pred + K@innovation\n",
        "      y_est[i, m] = x_est[0]\n",
        "  y_pred_err[j] = np.mean((train_y-y_pred)**2)\n",
        "  performance_df.loc[horizons[j], 'KF'] = y_pred_err[j]\n",
        "  performance_df.to_csv(file)\n",
        "  print(y_pred_err[j])\n",
        "  print('Horizon ' + str(horizons[j]/14) + ' ms done.')\n"
      ],
      "metadata": {
        "id": "-rYrB-bQIPQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bk5Ac3S8bvaJ",
        "n7iADEmD98Hh",
        "wpCSk4xB-KsH"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}